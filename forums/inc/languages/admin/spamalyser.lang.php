<?php

$l['guest'] = 'Guest';

$l['setting_group_spamalyser'] = 'Spamalyser Settings';
$l['setting_group_spamalyser_desc'] = '';
$l['setting_spamalyser_thresh_postcount'] = 'Post Count Threshold';
$l['setting_spamalyser_thresh_postcount_desc'] = 'Users with a post count higher than this number will always be assumed to be non-spammers.  Note that this uses MyBB\'s post count (so posts in forums with post counting disabled will not count).  Also note that this is applied after the post is made.';
$l['setting_spamalyser_thresh_onlinetime'] = 'Online Time (minutes) Threshold';
$l['setting_spamalyser_thresh_onlinetime_desc'] = 'Users with an online time higher than this number of minutes will always be assumed to be non-spammers.  Set to 0 to disable this check.';
$l['setting_spamalyser_thresh_regtime'] = 'Registration Age (hours) Threshold';
$l['setting_spamalyser_thresh_regtime_desc'] = 'Users who have been registered for longer than this time (in hours) will always be assumed to be non-spammers.  Set to 0 to disable this check.';
$l['setting_spamalyser_thresh_pms'] = 'Number of PMs Threshold';
$l['setting_spamalyser_thresh_pms_desc'] = 'Users who have more PMs than this number will always be assumed to be non-spammers.  Set to 0 to disable this check.';
$l['setting_spamalyser_groups'] = 'Groups to Moderate';
$l['setting_spamalyser_groups_desc'] = 'Only assume users (primary group only) from the following Group IDs may be spammers (generally, you should leave this as the default &quot;1,2,5&quot; which is the guests, registered users and awaiting activation groups, respectively).  Note that moderators will never be considered spammers.  Separate list with commas.';
$l['setting_spamalyser_safe_hosts'] = 'Ignored Hosts';
$l['setting_spamalyser_safe_hosts_desc'] = 'Links to the following hosts will be ignored in spam analysis.  Automatically includes subdomains, for example &quot;example.com&quot; will also consider &quot;www.example.com&quot; as a safe domain.  Separate multiple items with commas or newlines.  Use asterisk (*) to match arbitrary text (will not match dots, so &quot;example.*&quot; will match &quot;example.net&quot;, but not &quot;example.co.uk&quot;).  Also, you can use the <code>{COM}</code> shortcut (must be in uppercase) to match against common .com extension variants, eg example.com, example.de, example.co.uk, example.com.au etc (note: includes .co.cc)';
//$l['setting_spamalyser_thresh_links'] = 'Number of Links in Post Threshold';
//$l['setting_spamalyser_thresh_links_desc'] = 'Ignore posts containing this number of links, or fewer.  Default is 0, but you can increase this if you want to make spam checking less aggressive.';
$l['setting_spamalyser_weight_sig'] = 'Signature Weight Factor';
$l['setting_spamalyser_weight_sig_desc'] = 'If non-zero, will consider the poster\'s signature when calculating spam weighting - the value here determines how much weight the calculated spam weighting the the signature counts towards total spam weighting.  Note that duplicate linked keywords/hosts across post and signature are taken into consideration, if this option is enabled.
<br /><strong>Example</strong>: Calculated weighting of signature = 2, Signature weight factor = 1.5 =&gt; added weight will be 3';
$l['setting_spamalyser_weight_link'] = 'Weight Per Simple Link';
$l['setting_spamalyser_weight_link_desc'] = 'Likelihood of each &quot;simple link&quot; (eg <code>[url]http://example.com[/url]</code>) in a post making it a spam post.  For example, a value of 0.2 means that each link in the post gives it a +0.2 spam weighting.';
$l['setting_spamalyser_link_limit'] = 'Maximum Simple Link Weight';
$l['setting_spamalyser_link_limit_desc'] = 'If non-zero, will limit the maximum weight given to each simple link (including all bonuses from keywords/host etc) to the specified amount.  This helps limit situations where an innocent duplicate link containing many keywords triggers high weightings.';
$l['setting_spamalyser_weight_complexlink'] = 'Weight Per Complex Link';
$l['setting_spamalyser_weight_complexlink_desc'] = 'Likelihood of each &quot;complex link&quot; or link with custom text (eg <code>[url=http://example.com]link[/url]</code>) in a post making it a spam post.  Spammers tend to like putting their own text inside links, so we weight this more heavily by default.';
$l['setting_spamalyser_complexlink_limit'] = 'Maximum Complex Link Weight';
$l['setting_spamalyser_complexlink_limit_desc'] = 'Similar to the <em>Maximum Simple Link Weight</em> above, but for complex links.';
$l['setting_spamalyser_weight_samehost'] = 'Same Host Link Bias';
$l['setting_spamalyser_weight_samehost_desc'] = 'Penalise links to the same host more heavily, on a polynomial scale.  If <em>n</em>=[total number of links to this host] and <em>x</em>=[factor in below textbox], then the weight of each link to the same host will be multiplied by <em>n</em><sup><em>x</em>+1</sup> - <em>n</em> + 1
<br /><strong>Example</strong>: 3 links are posted, all pointing to <em>example.com</em>, same host link bias = 0.2 =&gt; weight of each link will be multiplied by 1.73719...';
$l['setting_spamalyser_weight_keyword'] = 'Duplicate Keyword Bias';
$l['setting_spamalyser_weight_keyword_desc'] = 'Penalise links containing duplicate keywords more heavily, on a polynomial scale.  Excludes safe keywords and bad keywords are weighted more heavily.  Similar to above setting, but is an additive weighting rather than multiplying link weights.
<br /><strong>Example</strong>: user posts <code>[url=http://example.com/]spam spam spam[/url]</code>, duplicate keyword bias = 0.2, =&gt; weight added (note, this is limited to the maximum link weight) will be 3 &times; (3<sup>1.2</sup> - 3) = 2.21158...';
$l['setting_spamalyser_weight_badword'] = 'Badword Weight Factor';
$l['setting_spamalyser_weight_badword_desc'] = 'Penalise links containing &quot;bad keywords&quot; more heavily.  Each link (and duplicate keyword) value is multiplied by the factor below. (see <em>Bad Keywords</em> setting for list of bad keywords)';
$l['setting_spamalyser_ignore_quotelinks'] = 'Ignore Quoted Links';
$l['setting_spamalyser_ignore_quotelinks_desc'] = 'If enabled, ignores links which appear inside quote tags.  Note that these links are cross checked with quoted posts, so this won\'t be fooled by spammers who add their links inside quote tags.  The following option affects whether all valid quoted links are ignored, or only those posted by &quot;safe&quot; users (those which pass any of the thresholds specified above).';
$l['setting_spamalyser_ignore_quotelinks_safe'] = 'Ignore valid quoted links from safe users only';
$l['setting_spamalyser_ignore_quotelinks_any'] = 'Ignore all valid quoted links';
$l['setting_spamalyser_ignore_quotelinks_off'] = 'Disabled (always consider quoted links in spam analysis)';
$l['setting_spamalyser_weight_editdiff'] = 'Edited Difference Bias';
$l['setting_spamalyser_weight_editdiff_desc'] = 'Some spammers like to post seemingly legitimate posts, and come back later to add links.  These are harder to detect, and unfortunately, many factors here will favour this activity.  This setting aims to correct this by adding a bias factor to links added through an edit.  When an edit occurs, the spam weighting is calculated for the previous message and the new one, and the difference in weightings is multiplied by the following factor and added to the overall weighting (note, this will never subtract anything if the difference is negative).  Setting this to 0 disables this feature.
<br /><strong>Example</strong>: weighting of original/previous message = 0.2, weighting of new message = 0.4, edited difference bias = 0.5 =&gt; this option will <em>add</em> 0.1 to message weighting (so it becomes 0.5)';
$l['setting_spamalyser_editdiff_grace'] = 'Edit Difference Grace Period';
$l['setting_spamalyser_editdiff_grace_desc'] = 'Affects the above setting; edits made within this period, measured in minutes from time of original post time, will not take the bias penalty.  This is to prevent the bias being added to quick edits, eg someone who forgot to add a link to their post.  Setting this to 0 disables the grace period.';
$l['setting_spamalyser_weight_oldbump'] = 'Weight Per Day for Bumping Old Thread';
$l['setting_spamalyser_weight_oldbump_desc'] = 'Sometimes a spammer will bump an old thread to post their filth.  If non-zero, this setting will add the specified amount to the post\'s weighting, multiplied by how long ago (in days) the last post was made.';
$l['setting_spamalyser_mweight_oldbump'] = 'Maximum Weight Applied for Bumping Old Thread';
$l['setting_spamalyser_mweight_oldbump_desc'] = 'To prevent a legitimate bump to a very old thread causing the above setting to go crazy, here\'s a maximum value to keep it sane.  Set to 0 to disable (no maximum).';
$l['setting_spamalyser_posthist_time'] = 'Consider Previous Posts - Time Limit';
$l['setting_spamalyser_posthist_time_desc'] = 'Set this value to <em>blank</em> (as in an empty field) to disable this feature.  If enabled, will consider the linked keywords/hosts in the user\'s previous posts in analysis.  This setting controls the time limit to search (in minutes) of the user\'s previous posts (time of posting or last edit).  0 means unlimited time (will grab ALL previous posts of the user)';
$l['setting_spamalyser_dforums'] = 'Special Forums';
$l['setting_spamalyser_dforums_desc'] = 'This setting allows you to specify a comma separated list of forum IDs whose weights are treated differently.  The overall spam weighting of each post (excluding user factors) will be multiplied by the factor in the next setting.  This can be used if spammers tend to prefer posting in a particular forum (eg first forum on the list).';
$l['setting_spamalyser_weight_dforums'] = 'Weight Factor of Special Forums';
$l['setting_spamalyser_weight_dforums_desc'] = 'Post made in &quot;Special Forums&quot; (above setting) will have their weight multiplied by the value of this setting.';
$l['setting_spamalyser_weight_sfs_username'] = 'SFS Username Frequency Weight';
$l['setting_spamalyser_weight_sfs_username_desc'] = 'Spam weighting is increased by this value multiplied by the number of times the poster\'s username appears in the SFS database.';
$l['setting_spamalyser_weight_sfs_email'] = 'SFS Email Frequency Weight';
$l['setting_spamalyser_weight_sfs_email_desc'] = 'Spam weighting is increased by this value multiplied by the number of times the poster\'s email appears in the SFS database.';
$l['setting_spamalyser_weight_sfs_ip'] = 'SFS IP Frequency Weight';
$l['setting_spamalyser_weight_sfs_ip_desc'] = 'Spam weighting is increased by this value multiplied by the number of times the poster\'s IP appears in the SFS database.';
$l['setting_spamalyser_sfs_limit'] = 'SFS Weighting Limit';
$l['setting_spamalyser_sfs_limit_desc'] = 'This setting allows you to set a maximum influence that the above SFS weightings have on the overall spam weighting of a post.  Set to 0 to disable.';
$l['setting_spamalyser_aki_key'] = 'Akismet API Key';
$l['setting_spamalyser_aki_key_desc'] = 'Akismet lookups require an <a href="http://akismet.com/wordpress/" target="_blank">API key</a>.  Enter your API key here (should be 12 hexadecimal (0-9 and a-f) characters) - note that Spamalyser assumes this key is valid if you supply one.  Akismet lookups are disabled if you do not supply a key here.';
$l['setting_spamalyser_weight_aki_spam'] = 'Akismet Spam Weighting';
$l['setting_spamalyser_weight_aki_spam_desc'] = 'Amount of weight to add if Akismet reports the post as spam.';
$l['setting_spamalyser_weight_aki_ham'] = 'Akismet Not Spam (aka Ham) Weighting';
$l['setting_spamalyser_weight_aki_ham_desc'] = 'Amount of weight to <strong>deduct</strong> if Akismet reports the post as not being spam. (note, I don\'t recommend entering a negative number here)';
$l['setting_spamalyser_aki_trigger_edit'] = 'Perform Akismet Lookup on Post Edits';
$l['setting_spamalyser_aki_trigger_edit_desc'] = 'If disabled (set to No), will only perform Akismet lookups on new threads/posts.  If enabled, will also perform lookups for post edits.';
$l['setting_spamalyser_weight_glang'] = 'Foreign Language Weighting';
$l['setting_spamalyser_weight_glang_desc'] = 'Sometimes you\'ll get spam in a foreign language.  If this setting is non-zero, Spamalyser will use Google\'s language detection to determine the language the post was made in.  If the language is foreign to your forum\'s native audience, there\'s a fair possibility of it being spam.  The following weighting will be multiplied by the \'confidence\' value (between 0 and 1) returned by Google.  Note that &quot;simple&quot; links will not be included in this lookup.';
$l['setting_spamalyser_glang_safe'] = 'Native Languages';
$l['setting_spamalyser_glang_safe_desc'] = 'Enter a comma separated list of <a href="http://code.google.com/apis/language/translate/v1/reference.html#LangNameArray">two-letter language codes</a> which are native to this forum.  This setting affects the above setting - languages not in this list will be considered foreign.';
$l['setting_spamalyser_weight_gsearch'] = 'Google Search Results Weighting';
$l['setting_spamalyser_weight_gsearch_desc'] = 'If you\'re getting spammed by something, chances are that many other forums are too.  We can therefore perform a Google search of what\'s been posted and use the number of results to give an indication of whether this is spam or not.  A high number of results is likely to indicate spam, whereas legitimate posts are unlikely to be posted across many sites. (note, do be careful of a copied article which you may consider legitimate)  If this value is non-zero, it\'ll be multiplied by the approximate number of Google search results and added to the weighting.  Note: searches are not performed through an API, so may potentially stop functioning in the future.  This feature is somewhat experimental.';
$l['setting_spamalyser_mweight_gsearch'] = 'Maximum Google Search Weighting';
$l['setting_spamalyser_mweight_gsearch_desc'] = 'If non-zero, ensures that huge result sets don\'t generate very high weightings by enforcing a maximum.';
$l['setting_spamalyser_gsearch_minlen'] = 'Minimum Google Search Message Length';
$l['setting_spamalyser_gsearch_minlen_desc'] = 'If non-zero, will only perform Google searches if the message length, in characters, is longer than the specified amount.  This is mainly to stop short posts triggering lots of results.';
$l['setting_spamalyser_weight_onlinetime'] = 'Online Time Weight Bias';
$l['setting_spamalyser_weight_onlinetime_desc'] = 'If non-zero, increases the spam weighting by the inverse of user\'s time online (in minutes) multiplied by the following factor.  Some spammers have very low online times, so this setting will help punish that action.
<br /><strong>Example</strong>: user online for 6 seconds (0.1 minutes) when post was made, online time weight bias = 0.3 =&gt; weight added will be 0.3/0.1 = 3';
$l['setting_spamalyser_weight_postcount'] = 'Post Count Weight Reduction';
$l['setting_spamalyser_weight_postcount_desc'] = 'If non-zero, reduces the spam weighting by the user\'s postcount multiplied by the following factor.';
$l['setting_spamalyser_weight_regtime'] = 'Registration Time Weight Reduction';
$l['setting_spamalyser_weight_regtime_desc'] = 'If non-zero, reduces the spam weighting by the user\'s time registered (in hours) multiplied by the following factor.';
$l['setting_spamalyser_weight_posttimes'] = 'Previous Post Ages Weight Reduction';
$l['setting_spamalyser_weight_posttimes_desc'] = 'If non-zero, reduces the spam weighting by the sum of ages of the user\'s previous posts/edits (in hours) multiplied by this factor.  Note that this reduction is only applied for new threads/posts (so ignored for edits) and ignores unapproved posts or those last edited by a moderator.  The idea of this setting is that if the user has a number of posts which have been active for a while without being moderated, this user is less likely to be a spammer.
<br /><strong>Example</strong>: user has already made two posts, one posted exactly 24 hours ago and the other posted exactly 1 hour ago - none of these have been moderated or edited by a moderator, previous post ages weight reduction = 0.2 =&gt; weight subtracted by this setting = (24+1) &times; 0.2 = 5';
$l['setting_spamalyser_posttimes_maxtime'] = 'Previous Post Age Limit';
$l['setting_spamalyser_posttimes_maxtime_desc'] = 'If non-zero, limits the weight reduction done by above setting with an upper bound to per-post age (in hours).  This tries to prevent a spammer from abusing the system by having some old seemingly legit posts to cause a large weight reduction.  For example, if set to 60 (2.5 days), a 5 day old post will be considered to have an age of only 60 hours for the above setting.';
$l['setting_spamalyser_weight_ipdiff'] = 'Registration IP Difference Weighting';
$l['setting_spamalyser_weight_ipdiff_desc'] = 'Some spammers like posting from vastly different IPs than the IP they registered with (perhaps it\'s proxy cycling or so that registrations can be manually done but spam submitted automatically).  This setting will punish this activity - spam weighting is increased the difference in bits between registration IP and posting IP. (for example, 25.1.1.1 and 25.2.1.1 have 18 bits worth of difference)  Only works for IPv4 addresses.';
$l['setting_spamalyser_weight_markreport'] = 'Marked Report Weight Reduction';
$l['setting_spamalyser_weight_markreport_desc'] = 'To try to reduce the amount of reports this plugin makes on a legit poster, reduce the final weighting, percentage-wise, by this amount for each read reported post of the user.  For example, if set to 0.2, the final weighting would be reduced by 20% for every report (of the users\' posts) which has been marked read, and haven\'t been unapproved; this also means that there will be no spam weighting once there are 5 marked reports for this user.  Note that two or more reports for the same post is only considered to be one report.  Post edits will also ignore any reports for the post being edited.';
$l['setting_spamalyser_tweight_report'] = 'Report Post Weighting Threshold';
$l['setting_spamalyser_tweight_report_desc'] = 'If the spam weight of a post exceeds this value, automatically report the post (uses MyBB\'s moderator reporting system).  Set to 0 to disable post reporting.';
$l['setting_spamalyser_tweight_unapprove'] = 'Unapprove Post Weighting Threshold';
$l['setting_spamalyser_tweight_unapprove_desc'] = 'If the spam weight of a post exceeds this value, automatically unapprove the post.  Set to 0 to disable post unapproving.';
$l['setting_spamalyser_tweight_block'] = 'Block Post Weighting Threshold';
$l['setting_spamalyser_tweight_block_desc'] = 'Blocks users attempting to make a post if the spam weight of the post exceeds this value.  Set to 0 to disable.';
$l['setting_spamalyser_no_block_edit'] = 'Never Block Post Edits';
$l['setting_spamalyser_no_block_edit_desc'] = 'If Yes, will disable blocking of post edits.  This may be useful if you wish to force bad post edits to be unapproved, whilst allowing the edit through.';
$l['setting_spamalyser_keyword_minlen'] = 'Keyword Minimum Length';
$l['setting_spamalyser_keyword_minlen_desc'] = 'Keywords shorter than this length are automatically ignored (will also affect the following two settings).';
$l['setting_spamalyser_keyword_safe'] = 'Ignored Keywords';
$l['setting_spamalyser_keyword_safe_desc'] = 'Words to not detect as keywords.  Generally, you should only place common participle terms here.  Separate them with commas.  Note that words only containing digits (such as &quot;2011&quot;) are not considered to be keywords.';
$l['setting_spamalyser_keyword_bad'] = 'Bad Keywords';
$l['setting_spamalyser_keyword_bad_desc'] = 'Comma separated list of keywords to be punished more heavily in spam weight calculation.';
$l['setting_spamalyser_report_uid'] = 'Reporter User ID';
$l['setting_spamalyser_report_uid_desc'] = 'User ID to use when reporting posts.';
$l['setting_spamalyser_report_nodupe'] = 'Don\'t Duplicate Report';
$l['setting_spamalyser_report_nodupe_desc'] = 'If the post already has an <em>unread</em> report (either via this plugin, or a user reporting the post), don\'t add another report to it.';

$l['spamalyser_settingsgrp_0'] = 'Thresholds and Exclusions';
$l['spamalyser_settingsgrp_1'] = 'Spam Weighting Factors';
$l['spamalyser_settingsgrp_2'] = 'Spam Weighting Factors (user)';
$l['spamalyser_settingsgrp_3'] = '<em>Stop Forum Spam</em> Lookups <span style="font-weight: normal;">(set all these to 0 to disable SFS lookups)</span>';
$l['spamalyser_settingsgrp_4'] = '<em>Akismet</em> Lookups';
$l['spamalyser_settingsgrp_5'] = '<em>Google</em> Lookups';
$l['spamalyser_settingsgrp_8'] = 'Spam Detection Actions';
$l['spamalyser_settingsgrp_9'] = 'Misc Options';

$l['spamalyser_logs'] = 'Spamalyser Log';
$l['spamalyser_logs_desc'] = 'This is where you can find both delicious spam and ham.';
$l['prune_spamalyser_logs'] = 'Prune Spamalyser Log';
$l['prune_spamalyser_logs_desc'] = 'Use this to get rid of stale or rotten spam/ham.';
$l['view_spamalyser_logitem'] = 'View Spamalyser Log Item';
$l['filter_spamalyser_logs'] = 'Filter Spamalyser Log';
$l['no_spamalyserlogs'] = 'No log entries were found with the specified criteria.';
$l['weighting'] = 'Spam weighting';
$l['icon_new_thread_post'] = 'New Thread/Post';
$l['icon_alt_new_thread_post'] = '[N]';
$l['icon_edit_thread_post'] = 'Edit Thread/Post';
$l['icon_alt_edit_thread_post'] = '[E]';
$l['icon_merge_post'] = 'Auto-merged Post';
$l['icon_alt_merge_post'] = '[M]';
$l['icon_post_unapproved'] = 'Post unapproved';
$l['icon_post_deleted'] = 'Post deleted or doesn\'t exist';
$l['icon_action_blocked'] = 'Post/edit was blocked';
$l['icon_action_blocked_alt'] = '[blk]';
$l['icon_action_errors'] = 'Post contained other errors so never went through';
$l['icon_action_errors_alt'] = '[err]';
$l['icon_action_reported'] = 'Post was reported';
$l['icon_action_reported_alt'] = '[rpt]';
$l['icon_action_unapproved'] = 'Post was unapproved';
$l['icon_action_unapproved_alt'] = '[hid]';
$l['success_pruned_spamalyser_logs'] = 'The stale meat has been sent to the furnace.';
$l['can_view_spamalyserlog'] = 'Can view Spamalyser log';
$l['error_invalid_logitem'] = 'Invalid log item ID';

$l['weighting_calculation'] = 'Weighting Calculation';
$l['weighting_component'] = 'Component';
$l['weighting_amount'] = 'Weighting';
$l['weighting_overall'] = 'Overall';
$l['weighting_postcount'] = 'Post Count Weighting';
$l['weighting_onlinetime'] = 'Online Time Weighting';
$l['weighting_regtime'] = 'Registration Time Weighting';
$l['weighting_ipdiff'] = 'IP Difference Weighting';
$l['weighting_oldbump'] = 'Old Thread Bump Weighting';
$l['weighting_posttimes'] = 'Previous Post/Edit Ages Weighting';
$l['weighting_sig'] = 'Signature Weighting';
$l['weighting_msg'] = 'Post Message Weighting';
$l['weighting_editbonus'] = 'Edited Post Difference Weighting';
$l['weighting_sfs'] = '<em>Stop Forum Spam</em> Weighting';
$l['weighting_akismet'] = '<em>Akismet</em> Weighting';
$l['weighting_google_lang'] = '<em>Google</em> Foreign Language Detection Weighting';
$l['weighting_google_search'] = '<em>Google</em> Search Weighting';
//$l['weighting_post'] = '<em>Overall Post Weighting</em> (before forum multiplier)';
$l['weighting_markedreports'] = 'Marked Reports Weighting';
$l['post_message'] = 'Post Message';
$l['view_full_post'] = 'View full post message';
$l['http_info'] = 'HTTP Request Headers';
$l['request_ip'] = 'Request IP';

$l['spamalyser_prunelogtask_name'] = 'Prune Spamalyser Log';
$l['spamalyser_prunelogtask_desc'] = 'Keeps flies away by removing old Spamalyser log entries.';
